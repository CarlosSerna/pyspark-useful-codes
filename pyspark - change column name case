import re


def to_pascal_case_respecting_existing(name: str) -> str:
    """
    Converts a column name to PascalCase, preserving words that are already PascalCase.

    Examples:
    ---------
    'x_account_id' → 'XAccountId'
    'cpu_cores' → 'CpuCores'
    'X_AccountId' → 'XAccountId'
    'X_BilledCostInUsd' → 'XBilledCostInUsd'
    'XAccountId' → 'XAccountId' (preserved as-is)

    Parameters:
    -----------
    name : str
        Input column name with any format.

    Returns:
    --------
    str
        Column name converted to PascalCase, respecting existing casing of subwords.
    """
    # Step 1: If already PascalCase and has no delimiters, return as-is
    if re.fullmatch(r'[A-Z][a-zA-Z0-9]*', name) and not any(sep in name for sep in ['_', '-', '.', ' ']):
        return name

    # Step 2: Normalize all separators to space
    name = re.sub(r"[.\-_\s]+", " ", name)

    # Step 3: Split by space and preserve casing if already PascalCase
    words = re.split(r"\s+", name.strip())

    result = []
    for word in words:
        if not word:
            continue
        # If already PascalCase, keep it
        if re.fullmatch(r'[A-Z][a-z0-9]+(?:[A-Z][a-z0-9]+)*', word):
            result.append(word)
        else:
            # Otherwise capitalize
            result.append(word.capitalize())

    return ''.join(result)


import re

def to_snake_case(column_name: str) -> str:
    # Remove leading/trailing whitespace
    name = column_name.strip()

    # Replace spaces and hyphens with underscores
    name = re.sub(r"[ \-]+", "_", name)

    # Handle camelCase and PascalCase to snake_case
    name = re.sub(r"(.)([A-Z][a-z]+)", r"\1_\2", name)
    name = re.sub(r"([a-z0-9])([A-Z])", r"\1_\2", name)

    # Remove double underscores from previous steps
    name = re.sub(r"__+", "_", name)

    # Convert to lowercase
    name = name.lower()

    return name




def standardize_column_names_to_pascal_case(df):
    """
    Converts all column names in a Spark DataFrame to PascalCase,
    preserving subwords already in PascalCase.

    Parameters:
    -----------
    df : pyspark.sql.DataFrame

    Returns:
    --------
    pyspark.sql.DataFrame
        DataFrame with PascalCase column names.
    """
    new_names = [to_pascal_case_respecting_existing(c) for c in df.columns]
    return df.toDF(*new_names)

def standardize_columns_names_to_snake_case(df):
    renamed_cols = [to_snake_case(col) for col in df.columns]
    return df.toDF(*renamed_cols)
